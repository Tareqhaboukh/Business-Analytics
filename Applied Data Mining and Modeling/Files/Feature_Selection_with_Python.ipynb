{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.11",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "### Feature Selection with Python\n",
                "\n",
                "Feature selection methods in Python  \n",
                "Tareq Haboukh"
            ],
            "metadata": {
                "azdata_cell_guid": "1647641c-931f-43ad-8472-6e92f13fddae"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "from sklearn.feature_selection import VarianceThreshold\n",
                "from itertools import compress\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.metrics import classification_report, accuracy_score, mean_squared_error, confusion_matrix\n",
                "\n",
                "Dataset = pd.read_csv(\"Dataset.csv\")\n",
                "df = pd.DataFrame(Dataset)"
            ],
            "metadata": {
                "azdata_cell_guid": "731c9d88-3a78-4081-b6d9-811404fd614a",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 5
        },
        {
            "cell_type": "code",
            "source": [
                "def Logistic_Regression():\n",
                "\n",
                "    y = df.loc[:, df.columns == 'gnd']\n",
                "    x = df.loc[:, (df.columns != 'gnd') & (df.columns !='ID')]\n",
                "\n",
                "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
                "    \n",
                "    lr_model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
                "    lr_model.fit(x_train, y_train.values.ravel())\n",
                "    \n",
                "    y_pred = lr_model.predict(x_test)\n",
                "    \n",
                "    accuracy = accuracy_score(y_test, y_pred)\n",
                "    print(\"Accuracy of the logistic regression model on test set: %3f\" %accuracy)"
            ],
            "metadata": {
                "azdata_cell_guid": "022ac6f6-1653-4c66-b867-69fc3247cd32",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 1
        },
        {
            "cell_type": "code",
            "source": [
                "def Logistic_Regression_Variance_filter(VT):\n",
                "    selector = VarianceThreshold(threshold=VT)\n",
                "    selected_features = selector.fit_transform(df)\n",
                "    selector.get_params()\n",
                "\n",
                "    features_selected_VarianceThreshold = list(compress(df.columns, selector.get_support()))\n",
                "\n",
                "    df_new = df.filter(features_selected_VarianceThreshold)\n",
                "    y = df_new.loc[:, df_new.columns == 'gnd']\n",
                "    x = df_new.loc[:, (df_new.columns != 'gnd') & (df_new.columns !='ID')]\n",
                "\n",
                "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
                "\n",
                "    lr_model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
                "    lr_model.fit(x_train, y_train.values.ravel())\n",
                "    \n",
                "    y_pred = lr_model.predict(x_test)    \n",
                "    \n",
                "    # Model Accuracy\n",
                "    accuracy = accuracy_score(y_test, y_pred)\n",
                "    return(VT,accuracy)"
            ],
            "metadata": {
                "azdata_cell_guid": "3d94d00e-4433-4002-97be-a492ed578d1c",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 2
        },
        {
            "cell_type": "code",
            "source": [
                "# Low Variance Filter\n",
                "def low_variance_filter(threshold):\n",
                "    variance = df.var()\n",
                "    features = df.columns\n",
                "    selectedVariables = []\n",
                "    for i in range(0, len(df.columns)):\n",
                "        if variance[i] >= threshold:\n",
                "            selectedVariables.append(features[i])\n",
                "    return selectedVariables"
            ],
            "metadata": {
                "azdata_cell_guid": "31c2c53b-36cf-438b-a799-06ebc282ce76",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 3
        },
        {
            "cell_type": "code",
            "source": [
                "df.rename(columns = {'Unnamed: 0' : 'ID'}, inplace = True)"
            ],
            "metadata": {
                "azdata_cell_guid": "b14704dc-a2b9-48ce-b446-7f85a1b75f3f",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 6
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### 1. Look at the shape of the dataset and print out the number of features. (gnd is the target variable)"
            ],
            "metadata": {
                "azdata_cell_guid": "26d931e8-c1cb-4204-baa9-1d6e6380ecde"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "df.shape"
            ],
            "metadata": {
                "azdata_cell_guid": "c7252e7c-2977-49e5-a05b-04226c9582f5",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 7,
                    "data": {
                        "text/plain": "(800, 258)"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 7
        },
        {
            "cell_type": "code",
            "source": [
                "features_count = df.columns.str.contains(\"fea.\").sum()\n",
                "print(\"The dataset has {}\".format(features_count) + \" features\")"
            ],
            "metadata": {
                "scrolled": true,
                "azdata_cell_guid": "aa79c246-653f-4ff6-a468-969f30fe3c48",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "The dataset has 256 features\n"
                }
            ],
            "execution_count": 8
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### 2. Apply the Logistic Regression model on the given dataset and get the accuracy of the model."
            ],
            "metadata": {
                "azdata_cell_guid": "b821ec79-d1b8-4784-9241-93916fbcf9fb"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "Logistic_Regression()"
            ],
            "metadata": {
                "azdata_cell_guid": "d34ecc5e-2a21-429e-b30c-8b0e801eebab",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Accuracy of the logistic regression model on test set: 0.987500\n"
                }
            ],
            "execution_count": 9
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### 3. Remove low variance features set the threshold = 0.1, 0.2, 0.3, and 0.4"
            ],
            "metadata": {
                "azdata_cell_guid": "14402a80-ee4a-4d46-8de9-abc9ebe4b7a7"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Threshold = 0.1\n",
                "Threshold_1 = low_variance_filter(0.1)\n",
                "\n",
                "# Threshold = 0.2\n",
                "Threshold_2 = low_variance_filter(0.2)\n",
                "\n",
                "# Threshold = 0.3\n",
                "Threshold_3 = low_variance_filter(0.3)\n",
                "\n",
                "# Threshold = 0.4\n",
                "Threshold_4 = low_variance_filter(0.4)"
            ],
            "metadata": {
                "azdata_cell_guid": "dbdc2f74-3732-431c-a223-20470272ffd7",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 11
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### 4. Print out the new datasets with selected features."
            ],
            "metadata": {
                "azdata_cell_guid": "6c479a19-410b-4fb2-8dac-15a6aa23cb32"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Dataset with 0.1 Variance Threshold\n",
                "df[Threshold_1].head()"
            ],
            "metadata": {
                "azdata_cell_guid": "3a50bb9c-3337-4687-b2d8-bb495c4d14a4",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 13,
                    "data": {
                        "text/plain": "   ID     fea.5     fea.6     fea.7     fea.8     fea.9    fea.10    fea.11  \\\n0   1 -0.774192 -0.275283  0.034194 -0.399883 -0.815319 -0.955680 -0.989120   \n1   2 -0.901515 -0.545999  0.030940  0.411866  0.390567  0.008434 -0.502208   \n2   3 -0.961828 -0.717215 -0.144694  0.092191 -0.260683 -0.687438 -0.925676   \n3   4 -0.832602 -0.368054 -0.080497 -0.246663 -0.263954 -0.317376 -0.699568   \n4   5 -0.988678 -0.829627 -0.330878  0.013998 -0.345315 -0.803120 -0.973332   \n\n     fea.19    fea.20  ...   fea.244   fea.245   fea.246   fea.247   fea.248  \\\n0 -0.987214 -0.844745  ... -0.183571  0.170864  0.365778  0.414430  0.427150   \n1 -0.997706 -0.952953  ... -0.979200 -0.858993 -0.527557 -0.043773  0.358344   \n2 -0.986465 -0.932243  ... -0.894444 -0.636530 -0.257442  0.153603  0.414912   \n3 -0.999915 -0.992487  ... -0.942932 -0.684969 -0.164910  0.306974  0.480128   \n4 -0.999992 -0.999126  ... -0.999747 -0.988999 -0.851968 -0.406307  0.080920   \n\n    fea.249   fea.250   fea.251   fea.252  gnd  \n0  0.404087  0.213519 -0.104366 -0.444652    0  \n1  0.374951 -0.040142 -0.586220 -0.911391    0  \n2  0.334299 -0.060454 -0.541605 -0.867137    0  \n3  0.487418  0.356270 -0.015310 -0.530088    0  \n4  0.086649 -0.458626 -0.885111 -0.993165    0  \n\n[5 rows x 209 columns]",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>fea.5</th>\n      <th>fea.6</th>\n      <th>fea.7</th>\n      <th>fea.8</th>\n      <th>fea.9</th>\n      <th>fea.10</th>\n      <th>fea.11</th>\n      <th>fea.19</th>\n      <th>fea.20</th>\n      <th>...</th>\n      <th>fea.244</th>\n      <th>fea.245</th>\n      <th>fea.246</th>\n      <th>fea.247</th>\n      <th>fea.248</th>\n      <th>fea.249</th>\n      <th>fea.250</th>\n      <th>fea.251</th>\n      <th>fea.252</th>\n      <th>gnd</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>-0.774192</td>\n      <td>-0.275283</td>\n      <td>0.034194</td>\n      <td>-0.399883</td>\n      <td>-0.815319</td>\n      <td>-0.955680</td>\n      <td>-0.989120</td>\n      <td>-0.987214</td>\n      <td>-0.844745</td>\n      <td>...</td>\n      <td>-0.183571</td>\n      <td>0.170864</td>\n      <td>0.365778</td>\n      <td>0.414430</td>\n      <td>0.427150</td>\n      <td>0.404087</td>\n      <td>0.213519</td>\n      <td>-0.104366</td>\n      <td>-0.444652</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>-0.901515</td>\n      <td>-0.545999</td>\n      <td>0.030940</td>\n      <td>0.411866</td>\n      <td>0.390567</td>\n      <td>0.008434</td>\n      <td>-0.502208</td>\n      <td>-0.997706</td>\n      <td>-0.952953</td>\n      <td>...</td>\n      <td>-0.979200</td>\n      <td>-0.858993</td>\n      <td>-0.527557</td>\n      <td>-0.043773</td>\n      <td>0.358344</td>\n      <td>0.374951</td>\n      <td>-0.040142</td>\n      <td>-0.586220</td>\n      <td>-0.911391</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>-0.961828</td>\n      <td>-0.717215</td>\n      <td>-0.144694</td>\n      <td>0.092191</td>\n      <td>-0.260683</td>\n      <td>-0.687438</td>\n      <td>-0.925676</td>\n      <td>-0.986465</td>\n      <td>-0.932243</td>\n      <td>...</td>\n      <td>-0.894444</td>\n      <td>-0.636530</td>\n      <td>-0.257442</td>\n      <td>0.153603</td>\n      <td>0.414912</td>\n      <td>0.334299</td>\n      <td>-0.060454</td>\n      <td>-0.541605</td>\n      <td>-0.867137</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>-0.832602</td>\n      <td>-0.368054</td>\n      <td>-0.080497</td>\n      <td>-0.246663</td>\n      <td>-0.263954</td>\n      <td>-0.317376</td>\n      <td>-0.699568</td>\n      <td>-0.999915</td>\n      <td>-0.992487</td>\n      <td>...</td>\n      <td>-0.942932</td>\n      <td>-0.684969</td>\n      <td>-0.164910</td>\n      <td>0.306974</td>\n      <td>0.480128</td>\n      <td>0.487418</td>\n      <td>0.356270</td>\n      <td>-0.015310</td>\n      <td>-0.530088</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>-0.988678</td>\n      <td>-0.829627</td>\n      <td>-0.330878</td>\n      <td>0.013998</td>\n      <td>-0.345315</td>\n      <td>-0.803120</td>\n      <td>-0.973332</td>\n      <td>-0.999992</td>\n      <td>-0.999126</td>\n      <td>...</td>\n      <td>-0.999747</td>\n      <td>-0.988999</td>\n      <td>-0.851968</td>\n      <td>-0.406307</td>\n      <td>0.080920</td>\n      <td>0.086649</td>\n      <td>-0.458626</td>\n      <td>-0.885111</td>\n      <td>-0.993165</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 209 columns</p>\n</div>"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 13
        },
        {
            "cell_type": "code",
            "source": [
                "# Dataset with 0.2 Variance Threshold\n",
                "df[Threshold_2].head()"
            ],
            "metadata": {
                "azdata_cell_guid": "718facb2-f7ec-4970-92e3-addb02627a9b",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 14,
                    "data": {
                        "text/plain": "   ID     fea.6     fea.7    fea.20    fea.21    fea.22    fea.23    fea.24  \\\n0   1 -0.275283  0.034194 -0.844745 -0.336824  0.331032  0.504431  0.130807   \n1   2 -0.545999  0.030940 -0.952953 -0.659959  0.035736  0.653449  0.839105   \n2   3 -0.717215 -0.144694 -0.932243 -0.783630 -0.349874  0.450019  0.764206   \n3   4 -0.368054 -0.080497 -0.992487 -0.873086 -0.403134  0.222510  0.448349   \n4   5 -0.829627 -0.330878 -0.999126 -0.970712 -0.667495  0.090387  0.504988   \n\n     fea.25    fea.26  ...   fea.235   fea.236   fea.237   fea.245   fea.246  \\\n0 -0.319797 -0.623297  ...  0.522361  0.366751 -0.082735  0.170864  0.365778   \n1  0.688151  0.494709  ...  0.013770 -0.672177 -0.956167 -0.858993 -0.527557   \n2  0.530335 -0.029652  ...  0.208939 -0.459925 -0.888110 -0.636530 -0.257442   \n3  0.516625  0.364233  ...  0.632486  0.047866 -0.706772 -0.684969 -0.164910   \n4  0.267632 -0.399843  ... -0.718008 -0.980233 -0.999657 -0.988999 -0.851968   \n\n    fea.247   fea.248   fea.249   fea.250  gnd  \n0  0.414430  0.427150  0.404087  0.213519    0  \n1 -0.043773  0.358344  0.374951 -0.040142    0  \n2  0.153603  0.414912  0.334299 -0.060454    0  \n3  0.306974  0.480128  0.487418  0.356270    0  \n4 -0.406307  0.080920  0.086649 -0.458626    0  \n\n[5 rows x 182 columns]",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>fea.6</th>\n      <th>fea.7</th>\n      <th>fea.20</th>\n      <th>fea.21</th>\n      <th>fea.22</th>\n      <th>fea.23</th>\n      <th>fea.24</th>\n      <th>fea.25</th>\n      <th>fea.26</th>\n      <th>...</th>\n      <th>fea.235</th>\n      <th>fea.236</th>\n      <th>fea.237</th>\n      <th>fea.245</th>\n      <th>fea.246</th>\n      <th>fea.247</th>\n      <th>fea.248</th>\n      <th>fea.249</th>\n      <th>fea.250</th>\n      <th>gnd</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>-0.275283</td>\n      <td>0.034194</td>\n      <td>-0.844745</td>\n      <td>-0.336824</td>\n      <td>0.331032</td>\n      <td>0.504431</td>\n      <td>0.130807</td>\n      <td>-0.319797</td>\n      <td>-0.623297</td>\n      <td>...</td>\n      <td>0.522361</td>\n      <td>0.366751</td>\n      <td>-0.082735</td>\n      <td>0.170864</td>\n      <td>0.365778</td>\n      <td>0.414430</td>\n      <td>0.427150</td>\n      <td>0.404087</td>\n      <td>0.213519</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>-0.545999</td>\n      <td>0.030940</td>\n      <td>-0.952953</td>\n      <td>-0.659959</td>\n      <td>0.035736</td>\n      <td>0.653449</td>\n      <td>0.839105</td>\n      <td>0.688151</td>\n      <td>0.494709</td>\n      <td>...</td>\n      <td>0.013770</td>\n      <td>-0.672177</td>\n      <td>-0.956167</td>\n      <td>-0.858993</td>\n      <td>-0.527557</td>\n      <td>-0.043773</td>\n      <td>0.358344</td>\n      <td>0.374951</td>\n      <td>-0.040142</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>-0.717215</td>\n      <td>-0.144694</td>\n      <td>-0.932243</td>\n      <td>-0.783630</td>\n      <td>-0.349874</td>\n      <td>0.450019</td>\n      <td>0.764206</td>\n      <td>0.530335</td>\n      <td>-0.029652</td>\n      <td>...</td>\n      <td>0.208939</td>\n      <td>-0.459925</td>\n      <td>-0.888110</td>\n      <td>-0.636530</td>\n      <td>-0.257442</td>\n      <td>0.153603</td>\n      <td>0.414912</td>\n      <td>0.334299</td>\n      <td>-0.060454</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>-0.368054</td>\n      <td>-0.080497</td>\n      <td>-0.992487</td>\n      <td>-0.873086</td>\n      <td>-0.403134</td>\n      <td>0.222510</td>\n      <td>0.448349</td>\n      <td>0.516625</td>\n      <td>0.364233</td>\n      <td>...</td>\n      <td>0.632486</td>\n      <td>0.047866</td>\n      <td>-0.706772</td>\n      <td>-0.684969</td>\n      <td>-0.164910</td>\n      <td>0.306974</td>\n      <td>0.480128</td>\n      <td>0.487418</td>\n      <td>0.356270</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>-0.829627</td>\n      <td>-0.330878</td>\n      <td>-0.999126</td>\n      <td>-0.970712</td>\n      <td>-0.667495</td>\n      <td>0.090387</td>\n      <td>0.504988</td>\n      <td>0.267632</td>\n      <td>-0.399843</td>\n      <td>...</td>\n      <td>-0.718008</td>\n      <td>-0.980233</td>\n      <td>-0.999657</td>\n      <td>-0.988999</td>\n      <td>-0.851968</td>\n      <td>-0.406307</td>\n      <td>0.080920</td>\n      <td>0.086649</td>\n      <td>-0.458626</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 182 columns</p>\n</div>"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 14
        },
        {
            "cell_type": "code",
            "source": [
                "# Dataset with 0.3 Variance Threshold\n",
                "df[Threshold_3].head()"
            ],
            "metadata": {
                "azdata_cell_guid": "380b71eb-a886-405c-ab8c-032c11ba565a",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 15,
                    "data": {
                        "text/plain": "   ID    fea.21    fea.22    fea.26    fea.27    fea.37    fea.38    fea.43  \\\n0   1 -0.336824  0.331032 -0.623297 -0.835472  0.235636  0.540066 -0.274300   \n1   2 -0.659959  0.035736  0.494709  0.140118 -0.264202  0.538892  0.384775   \n2   3 -0.783630 -0.349874 -0.029652 -0.631342 -0.200933  0.200376 -0.038264   \n3   4 -0.873086 -0.403134  0.364233 -0.333441 -0.960678 -0.708190 -0.296770   \n4   5 -0.970712 -0.667495 -0.399843 -0.870560 -0.939941 -0.507406 -0.656211   \n\n     fea.44    fea.52  ...   fea.220   fea.221   fea.228   fea.229   fea.230  \\\n0 -0.644889 -0.081776  ...  0.505857  0.495046  0.339861  0.368924  0.320216   \n1 -0.081463 -0.657173  ... -0.221164 -0.808547 -0.866280 -0.422491  0.192044   \n2 -0.642408  0.240669  ...  0.051250 -0.718346 -0.482285  0.110328  0.541402   \n3 -0.865733 -0.999613  ...  0.376856 -0.547731 -0.787279 -0.161113  0.451871   \n4 -0.963497 -0.993818  ... -0.949420 -0.997999 -0.997320 -0.943469 -0.586251   \n\n    fea.231   fea.234   fea.235   fea.236  gnd  \n0  0.299545  0.518921  0.522361  0.366751    0  \n1  0.536542  0.611095  0.013770 -0.672177    0  \n2  0.769359  0.670917  0.208939 -0.459925    0  \n3  0.598882  0.788175  0.632486  0.047866    0  \n4  0.118789 -0.001911 -0.718008 -0.980233    0  \n\n[5 rows x 133 columns]",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>fea.21</th>\n      <th>fea.22</th>\n      <th>fea.26</th>\n      <th>fea.27</th>\n      <th>fea.37</th>\n      <th>fea.38</th>\n      <th>fea.43</th>\n      <th>fea.44</th>\n      <th>fea.52</th>\n      <th>...</th>\n      <th>fea.220</th>\n      <th>fea.221</th>\n      <th>fea.228</th>\n      <th>fea.229</th>\n      <th>fea.230</th>\n      <th>fea.231</th>\n      <th>fea.234</th>\n      <th>fea.235</th>\n      <th>fea.236</th>\n      <th>gnd</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>-0.336824</td>\n      <td>0.331032</td>\n      <td>-0.623297</td>\n      <td>-0.835472</td>\n      <td>0.235636</td>\n      <td>0.540066</td>\n      <td>-0.274300</td>\n      <td>-0.644889</td>\n      <td>-0.081776</td>\n      <td>...</td>\n      <td>0.505857</td>\n      <td>0.495046</td>\n      <td>0.339861</td>\n      <td>0.368924</td>\n      <td>0.320216</td>\n      <td>0.299545</td>\n      <td>0.518921</td>\n      <td>0.522361</td>\n      <td>0.366751</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>-0.659959</td>\n      <td>0.035736</td>\n      <td>0.494709</td>\n      <td>0.140118</td>\n      <td>-0.264202</td>\n      <td>0.538892</td>\n      <td>0.384775</td>\n      <td>-0.081463</td>\n      <td>-0.657173</td>\n      <td>...</td>\n      <td>-0.221164</td>\n      <td>-0.808547</td>\n      <td>-0.866280</td>\n      <td>-0.422491</td>\n      <td>0.192044</td>\n      <td>0.536542</td>\n      <td>0.611095</td>\n      <td>0.013770</td>\n      <td>-0.672177</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>-0.783630</td>\n      <td>-0.349874</td>\n      <td>-0.029652</td>\n      <td>-0.631342</td>\n      <td>-0.200933</td>\n      <td>0.200376</td>\n      <td>-0.038264</td>\n      <td>-0.642408</td>\n      <td>0.240669</td>\n      <td>...</td>\n      <td>0.051250</td>\n      <td>-0.718346</td>\n      <td>-0.482285</td>\n      <td>0.110328</td>\n      <td>0.541402</td>\n      <td>0.769359</td>\n      <td>0.670917</td>\n      <td>0.208939</td>\n      <td>-0.459925</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>-0.873086</td>\n      <td>-0.403134</td>\n      <td>0.364233</td>\n      <td>-0.333441</td>\n      <td>-0.960678</td>\n      <td>-0.708190</td>\n      <td>-0.296770</td>\n      <td>-0.865733</td>\n      <td>-0.999613</td>\n      <td>...</td>\n      <td>0.376856</td>\n      <td>-0.547731</td>\n      <td>-0.787279</td>\n      <td>-0.161113</td>\n      <td>0.451871</td>\n      <td>0.598882</td>\n      <td>0.788175</td>\n      <td>0.632486</td>\n      <td>0.047866</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>-0.970712</td>\n      <td>-0.667495</td>\n      <td>-0.399843</td>\n      <td>-0.870560</td>\n      <td>-0.939941</td>\n      <td>-0.507406</td>\n      <td>-0.656211</td>\n      <td>-0.963497</td>\n      <td>-0.993818</td>\n      <td>...</td>\n      <td>-0.949420</td>\n      <td>-0.997999</td>\n      <td>-0.997320</td>\n      <td>-0.943469</td>\n      <td>-0.586251</td>\n      <td>0.118789</td>\n      <td>-0.001911</td>\n      <td>-0.718008</td>\n      <td>-0.980233</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 133 columns</p>\n</div>"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 15
        },
        {
            "cell_type": "code",
            "source": [
                "# Dataset with 0.4 Variance Threshold\n",
                "df[Threshold_4].head()"
            ],
            "metadata": {
                "azdata_cell_guid": "0282fe39-b7ee-4dcd-a1ea-6faf52e06f40",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 16,
                    "data": {
                        "text/plain": "   ID    fea.43    fea.53    fea.54    fea.60    fea.69    fea.70    fea.72  \\\n0   1 -0.274300  0.537992  0.294486  0.015796  0.511609 -0.166338 -0.920920   \n1   2  0.384775  0.166035  0.792276  0.293105  0.484311  0.875532 -0.293676   \n2   3 -0.038264  0.613838  0.783930 -0.054780  0.950433  0.970910  0.861389   \n3   4 -0.296770 -0.984852 -0.800620 -0.927408 -0.945566 -0.611553  0.795796   \n4   5 -0.656211 -0.886214 -0.360784 -0.883866 -0.775522 -0.106894 -0.419718   \n\n     fea.76    fea.85  ...   fea.203   fea.204   fea.205   fea.212   fea.213  \\\n0  0.186746  0.241829  ... -0.582717 -0.143460  0.405317 -0.050328 -0.430388   \n1  0.413152  0.618632  ...  0.796826  0.345453 -0.523125 -0.599433  0.186843   \n2  0.546542  0.936660  ...  0.842856  0.311613 -0.580125  0.199657  0.624014   \n3 -0.885091 -0.822636  ...  0.544515  0.510231 -0.398164 -0.583682  0.302478   \n4 -0.759592 -0.685957  ... -0.349981 -0.878587 -0.993249 -0.989981 -0.832672   \n\n    fea.219   fea.220   fea.229   fea.230  gnd  \n0  0.195612  0.505857  0.368924  0.320216    0  \n1  0.518896 -0.221164 -0.422491  0.192044    0  \n2  0.713256  0.051250  0.110328  0.541402    0  \n3  0.749417  0.376856 -0.161113  0.451871    0  \n4 -0.549340 -0.949420 -0.943469 -0.586251    0  \n\n[5 rows x 52 columns]",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>fea.43</th>\n      <th>fea.53</th>\n      <th>fea.54</th>\n      <th>fea.60</th>\n      <th>fea.69</th>\n      <th>fea.70</th>\n      <th>fea.72</th>\n      <th>fea.76</th>\n      <th>fea.85</th>\n      <th>...</th>\n      <th>fea.203</th>\n      <th>fea.204</th>\n      <th>fea.205</th>\n      <th>fea.212</th>\n      <th>fea.213</th>\n      <th>fea.219</th>\n      <th>fea.220</th>\n      <th>fea.229</th>\n      <th>fea.230</th>\n      <th>gnd</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>-0.274300</td>\n      <td>0.537992</td>\n      <td>0.294486</td>\n      <td>0.015796</td>\n      <td>0.511609</td>\n      <td>-0.166338</td>\n      <td>-0.920920</td>\n      <td>0.186746</td>\n      <td>0.241829</td>\n      <td>...</td>\n      <td>-0.582717</td>\n      <td>-0.143460</td>\n      <td>0.405317</td>\n      <td>-0.050328</td>\n      <td>-0.430388</td>\n      <td>0.195612</td>\n      <td>0.505857</td>\n      <td>0.368924</td>\n      <td>0.320216</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.384775</td>\n      <td>0.166035</td>\n      <td>0.792276</td>\n      <td>0.293105</td>\n      <td>0.484311</td>\n      <td>0.875532</td>\n      <td>-0.293676</td>\n      <td>0.413152</td>\n      <td>0.618632</td>\n      <td>...</td>\n      <td>0.796826</td>\n      <td>0.345453</td>\n      <td>-0.523125</td>\n      <td>-0.599433</td>\n      <td>0.186843</td>\n      <td>0.518896</td>\n      <td>-0.221164</td>\n      <td>-0.422491</td>\n      <td>0.192044</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>-0.038264</td>\n      <td>0.613838</td>\n      <td>0.783930</td>\n      <td>-0.054780</td>\n      <td>0.950433</td>\n      <td>0.970910</td>\n      <td>0.861389</td>\n      <td>0.546542</td>\n      <td>0.936660</td>\n      <td>...</td>\n      <td>0.842856</td>\n      <td>0.311613</td>\n      <td>-0.580125</td>\n      <td>0.199657</td>\n      <td>0.624014</td>\n      <td>0.713256</td>\n      <td>0.051250</td>\n      <td>0.110328</td>\n      <td>0.541402</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>-0.296770</td>\n      <td>-0.984852</td>\n      <td>-0.800620</td>\n      <td>-0.927408</td>\n      <td>-0.945566</td>\n      <td>-0.611553</td>\n      <td>0.795796</td>\n      <td>-0.885091</td>\n      <td>-0.822636</td>\n      <td>...</td>\n      <td>0.544515</td>\n      <td>0.510231</td>\n      <td>-0.398164</td>\n      <td>-0.583682</td>\n      <td>0.302478</td>\n      <td>0.749417</td>\n      <td>0.376856</td>\n      <td>-0.161113</td>\n      <td>0.451871</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>-0.656211</td>\n      <td>-0.886214</td>\n      <td>-0.360784</td>\n      <td>-0.883866</td>\n      <td>-0.775522</td>\n      <td>-0.106894</td>\n      <td>-0.419718</td>\n      <td>-0.759592</td>\n      <td>-0.685957</td>\n      <td>...</td>\n      <td>-0.349981</td>\n      <td>-0.878587</td>\n      <td>-0.993249</td>\n      <td>-0.989981</td>\n      <td>-0.832672</td>\n      <td>-0.549340</td>\n      <td>-0.949420</td>\n      <td>-0.943469</td>\n      <td>-0.586251</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 52 columns</p>\n</div>"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 16
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### 5. Apply the Logistic Regression model on each of these datasets and get the accuracy scores."
            ],
            "metadata": {
                "azdata_cell_guid": "7ef777c7-62ef-4b9d-bee5-00da132b5839"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "yaxis = []\n",
                "xaxis = []\n",
                "\n",
                "variance_list = [0.1, 0.2, 0.3, 0.4]\n",
                "\n",
                "for i in variance_list:\n",
                "    x,y = Logistic_Regression_Variance_filter(i)\n",
                "    xaxis.append(x)\n",
                "    yaxis.append(y)\n",
                "    \n",
                "for i in range(len(xaxis)):\n",
                "    print(\"Variance: {} Model Accuracy: {}\".format(xaxis[i],yaxis[i].round(3)))"
            ],
            "metadata": {
                "azdata_cell_guid": "0b6d5c75-5531-4bf7-aaa6-5965b589a883",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Variance: 0.1 Model Accuracy: 0.988\nVariance: 0.2 Model Accuracy: 0.992\nVariance: 0.3 Model Accuracy: 0.988\nVariance: 0.4 Model Accuracy: 0.946\n"
                }
            ],
            "execution_count": 17
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### 6. Compare the accuracy scores and define does the feature selection improve the model or not."
            ],
            "metadata": {
                "azdata_cell_guid": "a1b0735d-d299-46fb-a32a-b3f0c88ad247"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "The differences between accuracies are small but it is worth mentioning that by increasing the variance threshold the accuracy tends to go lower usually at 0.4."
            ],
            "metadata": {
                "azdata_cell_guid": "0a8aa92b-6552-419f-ae27-bc24d2da5c55"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### 7. Show the of accuracy scores on a plot (line chart)."
            ],
            "metadata": {
                "azdata_cell_guid": "ee2a9092-fd6f-4cf0-9654-135dcfb82949"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "line_x = np.array(xaxis)\n",
                "line_y = np.array(yaxis)\n",
                "\n",
                "\n",
                "plt.plot(line_x,line_y)\n",
                "plt.title('Different Variance Accuracy Levels name')\n",
                "plt.xlabel('Var Threshold')\n",
                "plt.ylabel('Accuracy')\n",
                "plt.show()"
            ],
            "metadata": {
                "scrolled": true,
                "azdata_cell_guid": "2f3d8eb8-cc33-4572-a7e8-05d7bc266c65",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "<Figure size 432x288 with 1 Axes>",
                        "image/png": "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\n"
                    },
                    "metadata": {
                        "needs_background": "light"
                    }
                }
            ],
            "execution_count": 18
        }
    ]
}